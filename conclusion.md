---
layout: default
title: Conclusion & Additional Resources
nav_order: 7
---

# Congratulations

<!-- Edit this line to mention your workshop name -->
**Congratulations!** You've just finished this workshop.

You should now be able to:
* Perform initial data analysis on OCR text output
* Explain the importance of data provenance
* Apply computational techniques to correct common OCR errors
* Identify an appropriate data pre-processing approach


# Additional Resources
To learn more about any particular topic, take a look at the links below.

## OpenRefine

As we are using OpenRefine for our pre-processing tasks, having a better grasp of OpenRefine will assist your error correction effort! There are numerous tutorials available; the [Library Carpentries workshop on OpenRefine](https://librarycarpentry.org/lc-open-refine/) will reinforce your learning and gets into greater depth on some topics (though in a more general context - i.e. not specific to OCR error correction). 

You may also wish to refer to [the documentation for OpenRefine](https://docs.openrefine.org/) to really dive in to what's possible with the tool.


## Regular Expressions

Likewise, since one of the major OCR error correction strategies discussed involves using regular expressions (RegEx), a strong grasp of RegEx will help you make the most of OpenRefine. In addition to the resources listed on the "[Correcting OCR Errors with OpenRefine: Strategies](lessons/2b-or-strat#step3)" page: 

* Library Carpentries has also developed a [workshop on RegEx](https://librarycarpentry.org/lc-data-intro/),
* the [Rex Egg website](https://www.rexegg.com/regex-quickstart.html) offers both cheatsheets and comprehensive tutorials,
* Peter Green of Princeton University Library has developed a [RegEx cheatsheet tailored to OpenRefine](https://gist.github.com/pmgreen/6e133c5dcde65762d29c),
* another helpful resource, of course, is the [OpenRefine documentation](https://docs.openrefine.org/manual/expressions#regular-expressions).

You can also dynamically test your RegEx patterns with [Regular Expressions 101](https://regex101.com/) or [RegExr](https://regexr.com/).


## Critical Data Studies

If "[Behind the Interface](lessons/6-behind.html)" piqued your curiosity about how language frames our understanding of data, you may be interested in the following texts:

* Benjamin, Ruha. *Race after technology: Abolitionist tools for the new Jim code*. Polity, 2019. 
* Boyd, Danah, and Kate Crawford. "Critical questions for big data: Provocations for a cultural, technological, and scholarly phenomenon." *Information, communication & society* 15.5 (2012): 662-679.
* Fordyce, Robbie, and Suneel Jethani. "Critical data provenance as a methodology for studying how language conceals data ethics." *Continuum* 35.5 (2021): 775-787.
* Gitelman, Lisa, ed. *"Raw data" is an oxymoron*. MIT press, 2013.

## Related Workshops
* [Identifying Proper Nouns with Named Entity Recognition](https://scds.github.io/text-analysis-2/)
<!-- * [Exploring Themes with Topic Modeling](https://scds.github.io/text-analysis-3/)  -->
