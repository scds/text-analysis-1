---
layout: default
title: Lesson
nav_order: 3
has_children: true
has_toc: false
---

# Lesson Roadmap

1. An overview of the textual data analysis workflow
2. Data provenance
3. Initial Data Analysis (IDA)
4. Correcting OCR errors in scanned documents with OpenRefine
  * Basic tokenization (i.e. to work with unstructured text)
  * Regular Expressions (for consistent errors and removing unwanted characters)
  * Faceting and clustering (for slight misspellings and normalization)
5. OCR Error correction with Python 
6. Structuring text with TEI
<!-- 7. Behind the interface: data ‘cleaning’ and the anglo-centric bias of NLP; Born-digital texts -->

# Lesson Format

The hands-on components of the lesson are available as videos with written instructions and screenshots of the video content below. You are encouraged to watch the videos and use the written sections for later reference but feel free to approach the lesson however you prefer!

Next -> [An Overview of the Textual Analysis Workflow](overview.html)
