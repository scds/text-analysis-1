---
layout: home
title: Home
description: SCDS Do More with Digital Scholarship workshop series
nav_order: 1
---

<!-- Edit the content below for the workshop in question. Once you're ready to publish, remove the comment characters e.g. "<!--" at the start and end -->

<!--
<img src="assets/img/dmds-tableau.png" alt="Workshop Title Slide" width="720"> -->

# Welcome to Pre-Processing Textual Data. 

**Pre-Processing Textual Data belongs to a series of workshops on computational text analysis.**

We underestimate our abilities as humans to make sense of orthographic errors and alternative spellings like *thcn* or *shew*. Machines are less capable of making these inferences, meaning that [OCR](https://en.wikipedia.org/wiki/Optical_character_recognition) text output must often be corrected in the pre-processing stage of the textual analysis pipeline to render it legible to computational methods. 

In this lesson, we’ll use several approaches to correcting errors in the OCR text output and discuss when to use them. We’ll also introduce the concepts of exploratory data analysis (EDA) and data provenance, as well as the structuring of textual data with XML tags according to the Text Encoding Initiative (TEI) specifications.

## Learning Outcomes

By the end of the module, you will be able to:
* Perform initial data analysis on OCR text output
* Explain the importance of data provenance 
* Apply computational techniques to correct common OCR errors
* Identify an appropriate data pre-processing approach
* Encode unstructured textual data using [TEI markup](https://tei-c.org/guidelines/Customization/Lite/) (optional)

## Lesson Roadmap

1. An overview of the textual data analysis pipeline
1. Initial Data Analysis (IDA) and Exploratory Data Analysis (EDA)
1. Data provenance
1. VIDEO: Correcting OCR errors with scanned texts with OpenRefine
  * Basic tokenization (i.e. to work with unstructured text)
  * Regular Expressions (for consistent errors and removing unwanted characters)
  * Faceting and clustering (for slight misspellings and normalization)
5. VIDEO: Structuring text with TEI (optional)
6. Behind the interface: data ‘cleaning’ and the anglo-centric bias of NLP



